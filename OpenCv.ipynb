{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d84f5ed-ac57-476a-8b49-2126b71143f9",
   "metadata": {},
   "source": [
    "# OpenCv \n",
    "# Load image form pc and resize dimention then save in pc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd4ea1-f584-4a8d-85a8-f5b21a051e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\fev.png\")\n",
    "if image is not None:\n",
    "    # Set new width and height (for example: 300x350)\n",
    "    new_width = 300\n",
    "    new_height = 350\n",
    "    # Resize image\n",
    "    resized_image = cv2.resize(image, (new_width, new_height))\n",
    "    # Display resized image\n",
    "    cv2.imshow(\"Resized Image\", resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # Save the resized image (must include extension!)\n",
    "    success = cv2.imwrite(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\", resized_image)\n",
    "    if success:\n",
    "        print(\"Image saved successfully!\")\n",
    "    else:\n",
    "        print(\"Error: could not save image.\")\n",
    "else:\n",
    "    print(\"Error: image not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34216460-6d89-4f10-99d3-369c8133065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert in gray format (dont't save only show)\n",
    "import cv2\n",
    "image = cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\fev.png\")\n",
    "new_width = 300\n",
    "new_height = 350\n",
    "# Resize image\n",
    "resized_image = cv2.resize(image, (new_width, new_height))\n",
    "success = cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\", resized_image)\n",
    "if success is not None:\n",
    "    gray=cv2.cvtColor(success,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"GrayScale Image\", gray)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: image not convert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f8c16-e314-4533-bbc1-3cec6f54a1e0",
   "metadata": {},
   "source": [
    "# Image Transformation & Manipulation Techniqes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e60866e-7f45-4e4a-8a0c-8fb5d702e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing and Scaling Images -cv2.resize\n",
    "import cv2\n",
    "image = cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\")\n",
    "if image is not None:\n",
    "        print(\"Image loded successfully!\")\n",
    "        resized=cv2.resize(image,(400,450))\n",
    "        cv2.imshow(\"Orginal Image\", image)\n",
    "        cv2.imshow(\"Resize Image\", resized)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "         print(\"Error: could not lode image!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee753d5-b00b-469a-a565-14e7c9f81879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping Images using Slicing in OpenCv\n",
    "import cv2\n",
    "image = cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\")\n",
    "if image is not None:\n",
    "        cropped=image[50:400,50:450]\n",
    "        cv2.imshow(\"Cropped Image\", cropped)\n",
    "        cv2.imshow(\"Original Image\", image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "         print(\"Error: could not lode image!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87b8a4-a759-4eed-ac2a-95a5aef4f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Rotation and Flipping\n",
    "# Rotation\n",
    "import cv2\n",
    "image = cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\")\n",
    "if image is not None:\n",
    "        (h,w)=image.shape[:2]\n",
    "        center=(w/2,h/2)\n",
    "        m=cv2.getRotationMatrix2D(center,90,1.0)\n",
    "        rotated=cv2.warpAffine(image,m,(w,h))\n",
    "        cv2.imshow(\"Orginal Image\", image)\n",
    "        cv2.imshow(\"Rotated 90 degree\", rotated)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "         print(\"Error: could not lode image!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6266a1-3c42-4011-8f38-8b1aaa4e7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Rotation and Flipping\n",
    "# Flipping\n",
    "import cv2\n",
    "image = cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\")\n",
    "if image is not None:\n",
    "        flipped_horizontal=cv2.flip(image,1)\n",
    "        flipped_vertical=cv2.flip(image,0)\n",
    "        flipped_both=cv2.flip(image,-1)\n",
    "        cv2.imshow(\"Orginal Image\", image)\n",
    "        cv2.imshow(\"flipped_horizontal\", flipped_horizontal)\n",
    "        cv2.imshow(\"flipped_vertical\", flipped_vertical)\n",
    "        cv2.imshow(\"flipped_both\", flipped_both)\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "         print(\"Error: could not lode image!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa7a42-6258-447e-bfa6-86d6e24734e4",
   "metadata": {},
   "source": [
    " # Basic Image Drowing Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b8ea2-ee5e-44b8-8b10-f9a6a009f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Drowing a Line - OpenCv\n",
    "#Syntax: cv2.line(img,pt1,pt2,color,thickness)\n",
    "import cv2\n",
    "image= cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\")\n",
    "if image is None:\n",
    "    print(\"Oops! Your image is not working\")\n",
    "else:\n",
    "    print(\"Image loaded successfully\")\n",
    "    pt1=(10,50) #(start point, margin Top right side)\n",
    "    pt2=(290,50)#(end point , margin Top left side)\n",
    "    color=(255,0,0) # BGR\n",
    "    thickness=2\n",
    "    cv2.line(image,pt1,pt2,color,thickness)\n",
    "    cv2.imshow(\"Line Drowing\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3d8f1-1bb3-43ca-8e96-307ce8017911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Drowing a Rectangle-OpenCv\n",
    "# Syntax: cv2.rectangle(img,pt1,pt2,color,thickness)\n",
    "import cv2\n",
    "image= cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\")\n",
    "if image is None:\n",
    "    print(\"Oops! Your image is not working\")\n",
    "else:\n",
    "    print(\"Image loaded successfully\")\n",
    "   # pt1=(100,50)\n",
    "   # pt2=(220,200)\n",
    "   # color=(255,0,0) # BGR\n",
    "   # thickness=2\n",
    "    cv2.rectangle(image,pt1=(100,50),pt2=(220,200),color=(255,0,0),thickness=2)\n",
    "    cv2.imshow(\"Rectangle Drowing\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8379a-14e0-43e8-ab67-7f647b8f715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Drowing a Circle-OpenCv\n",
    "# Syntax: cv2.circle(img,radius,color,thickness)\n",
    "import cv2\n",
    "image= cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\")\n",
    "if image is None:\n",
    "    print(\"Oops! Your image is not working\")\n",
    "else:\n",
    "    print(\"Image loaded successfully\")\n",
    "    cv2.circle(image,(160,130),60,(255,0,0),2)\n",
    "    cv2.imshow(\"Circle Drowing\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75dbde-96b4-4909-ae1f-541cc1a8e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Adding Text-OpenCv\n",
    "# Syntax: cv2.putText(img,text,org,font,fontScale,color,thickness)\n",
    "import cv2\n",
    "image= cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\")\n",
    "if image is None:\n",
    "    print(\"Oops! Your image is not working\")\n",
    "else:\n",
    "    print(\"Image loaded successfully\")\n",
    "    cv2.putText(image,\"Hello\",(220,160),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,200),2)\n",
    "    cv2.imshow(\"Circle Drowing\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3250c-fd83-4459-94da-3f887481e13a",
   "metadata": {},
   "source": [
    "# Video Processing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a9bf1-69a1-4dfb-9c56-99d4a8f1bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam Capture()\n",
    "# Syntax: cv2.VideoCapture(source)\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()#return =True or False  frame=image\n",
    "    if not ret:\n",
    "        print(\"Could not read frame\")\n",
    "        break\n",
    "    cv2.imshow(\"Webcam feed\",frame)\n",
    "    if cv2.waitKey(1)& 0xFF==ord('q'):\n",
    "        print(\"Cupture Stop\")\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21469f61-6a82-448b-8aa1-92eddd301039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Webcam Video to a File with OpenCv\n",
    "# Syntax: cv2.videoWriter(filename,codec,fps,frame_size)\n",
    "import cv2\n",
    "camera=cv2.VideoCapture(0)\n",
    "frame_width=int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height=int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "codec=cv2.VideoWriter_fourcc(*'XVID')\n",
    "recorder=cv2.VideoWriter(\"My_OpenCv_Video\",codec,20,(frame_width,frame_height))\n",
    "while True:\n",
    "    success,image=camera.read()\n",
    "    if not success:\n",
    "        break\n",
    "    recorder.write(image)\n",
    "    cv2.imshow(\"Recording Live\",image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "recorder.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e871a5-af13-4ca1-ad6f-00bc19b35295",
   "metadata": {},
   "source": [
    "# Image Filtering process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a4975-a6da-4704-83d4-bbdb5de20e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Blur\n",
    "# Syntax: blurred_image=cv2.GussianBlur(image,(kernel_size_x,kernel_size_y),sigma)\n",
    "import cv2\n",
    "image=cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\image desktop.jpg\")\n",
    "blurred=cv2.GaussianBlur(image,(7,7),0) # difalt is 0 arrgest according Gaussian Blure\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"Blurred Image\",blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2fa54-ed3a-4088-9b6c-5b7e69547e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Blur\n",
    "#Syntax: cv2.medianBlur(image,kernel_size)\n",
    "import cv2\n",
    "image=cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\image desktop.jpg\")\n",
    "median_blurred=cv2.medianBlur(image,3)\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"Median Blured Image\",median_blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154fe76-3ce3-4d08-84d0-e9d6ee88f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpening\n",
    "# Syntax: cv2.filter2D(image,ddepth,kernel)\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\image desktop.jpg\")\n",
    "sharpen_kernel=np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
    "sharpen_blurred=cv2.filter2D(image,-1,sharpen_kernel)\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"Sharpen Blured Image\",sharpen_blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2110d-df49-49ee-bdd5-5bc3d414979a",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b140946-5226-43b6-9b78-946a7d21f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge Detection -->  use for detect border ,separet object,frature extraction\n",
    "# Syntax: cv2.Canny(image,threshold1,threshold2)\n",
    "import cv2\n",
    "image=cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\",cv2.IMREAD_GRAYSCALE)\n",
    "edges=cv2.Canny(image,50,200)\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"Edges\",edges)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ce640-dc1f-4143-a9b1-6ee97b42c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding in OpenCv\n",
    "# Syntax: cv2.threshold(image,thres_value,max_value,method)\n",
    "import cv2\n",
    "image=cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\",cv2.IMREAD_GRAYSCALE)\n",
    "ret,thresh_img=cv2.threshold(image,120,255,cv2.THRESH_BINARY)  #90-0(black),130-255(white),180-255(white),50-0(black)\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"Thrshhold_image\",thresh_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b4f43-b291-4044-ad68-9b884c7056b7",
   "metadata": {},
   "source": [
    "# Bitwise Opretion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c94d98-c34d-491e-92f1-421a876bf7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.cv2.bitwise_and(img1,img2)\n",
    "# 2.cv2.bitwise_or(img1,img2)\n",
    "# 3.cv2.bitwise_not(img1)\n",
    "\n",
    "# img1,img2 height width same\n",
    "# use only black and white\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "img1=np.zeros((300,300),dtype=\"uint8\")\n",
    "img2=np.zeros((300,300),dtype=\"uint8\")\n",
    "\n",
    "cv2.circle(img1,(150,150),100,255,-1)\n",
    "cv2.rectangle(img2,(100,100),(250,250),255,-1)\n",
    "\n",
    "bitwise_and=cv2.bitwise_and(img1,img2)\n",
    "bitwise_or=cv2.bitwise_or(img1,img2)\n",
    "bitwise_not=cv2.bitwise_not(img1)\n",
    "\n",
    "cv2.imshow(\"Circle\", img1)\n",
    "cv2.imshow(\"Rectangle\",img2)\n",
    "cv2.imshow(\"AND\",bitwise_and)\n",
    "cv2.imshow(\"OR\",bitwise_or)\n",
    "cv2.imshow(\"NOT\",bitwise_not)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f5c377-f537-4380-850a-4e24d1fe757d",
   "metadata": {},
   "source": [
    "# Contours & Shape Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec869ee1-3d2e-42dc-868b-307133509066",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\resized_image.png\",cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58520c-b52d-488e-90cf-4e9125906d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding & Drowing Contours in OpenCv\n",
    "# Syntax: contours,hierarchy = cv2.findContours(image,mode,methode)\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\OIP.webp\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "_,thresh = cv2.threshold(gray,210,255,cv2.THRESH_BINARY)\n",
    "# FIND CONTOURS\n",
    "contours,heirarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.drawContours(img,contours,-1,(0,255,0),3)\n",
    "cv2.imshow(\"Contours\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082954e3-17dc-4993-bef3-6285debcbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROX\n",
    "# Syntax: approx=cv2.approxPolyDP(contour,epsilon,True)\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\New folder\\triangle_PNG95.png\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "_,thresh = cv2.threshold(gray,210,255,cv2.THRESH_BINARY)\n",
    "# FIND CONTOURS\n",
    "contours,heirarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.drawContours(img,contours,-1,(0,255,0),3)\n",
    "for contour in contours:\n",
    "    approx=cv2.approxPolyDP(contour,0.01 * cv2.arcLength(contour,True),True)\n",
    "    corners=len(approx)\n",
    "    if corners==3:\n",
    "        shape_name=\"Triangle\"\n",
    "    elif corners==4:\n",
    "        shape_name=\"Rectangle\"\n",
    "    elif corners==5:\n",
    "        shape_name=\"Pentagon\"\n",
    "    elif corners>5:\n",
    "        shape_name=\"Circle\"\n",
    "    else:\n",
    "       shape_name= \"Unknown\"\n",
    "    cv2.drawContours(img,[approx],0,(0,255,0),2)\n",
    "    x=approx.ravel()[0]\n",
    "    y=approx.ravel()[1]-10\n",
    "    cv2.putText(img,shape_name,(x,y),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,0),2)\n",
    "cv2.imshow(\"Contours\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c074b86-4032-4300-ab68-52ea7d3d16f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d774399-f5da-40c7-9302-bea5067c4c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84a7a9e-551f-40c0-a0e8-c2978a8a810c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a2393-2d21-44ee-8fe7-491ccaadbc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f5c57-07a6-42b4-99b7-93d3d0b21b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab7613a-90ca-481c-a943-00d96262ea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 cat, 184.2ms\n",
      "Speed: 25.1ms preprocess, 184.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 165.3ms\n",
      "Speed: 4.3ms preprocess, 165.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cat, 351.8ms\n",
      "Speed: 4.8ms preprocess, 351.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 126.7ms\n",
      "Speed: 3.6ms preprocess, 126.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 142.6ms\n",
      "Speed: 2.9ms preprocess, 142.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 120.5ms\n",
      "Speed: 3.4ms preprocess, 120.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 130.1ms\n",
      "Speed: 2.7ms preprocess, 130.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 122.7ms\n",
      "Speed: 4.5ms preprocess, 122.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 129.8ms\n",
      "Speed: 3.0ms preprocess, 129.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 120.4ms\n",
      "Speed: 2.9ms preprocess, 120.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.3ms\n",
      "Speed: 2.8ms preprocess, 128.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 114.8ms\n",
      "Speed: 2.8ms preprocess, 114.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.9ms\n",
      "Speed: 3.2ms preprocess, 127.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 118.8ms\n",
      "Speed: 3.0ms preprocess, 118.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 127.0ms\n",
      "Speed: 2.7ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 119.2ms\n",
      "Speed: 3.0ms preprocess, 119.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 124.3ms\n",
      "Speed: 2.8ms preprocess, 124.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 118.6ms\n",
      "Speed: 2.9ms preprocess, 118.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.5ms\n",
      "Speed: 2.8ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 125.1ms\n",
      "Speed: 2.7ms preprocess, 125.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.2ms\n",
      "Speed: 2.8ms preprocess, 127.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 116.1ms\n",
      "Speed: 2.8ms preprocess, 116.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.4ms\n",
      "Speed: 3.0ms preprocess, 131.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 120.7ms\n",
      "Speed: 2.8ms preprocess, 120.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 125.6ms\n",
      "Speed: 2.9ms preprocess, 125.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 116.7ms\n",
      "Speed: 2.9ms preprocess, 116.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.6ms\n",
      "Speed: 2.6ms preprocess, 125.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 112.4ms\n",
      "Speed: 2.8ms preprocess, 112.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.1ms\n",
      "Speed: 2.9ms preprocess, 126.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 118.5ms\n",
      "Speed: 2.9ms preprocess, 118.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.2ms\n",
      "Speed: 2.6ms preprocess, 129.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 133.2ms\n",
      "Speed: 4.3ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.7ms\n",
      "Speed: 2.8ms preprocess, 128.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 128.2ms\n",
      "Speed: 3.0ms preprocess, 128.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 dog, 142.0ms\n",
      "Speed: 2.9ms preprocess, 142.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 128.6ms\n",
      "Speed: 3.0ms preprocess, 128.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 135.0ms\n",
      "Speed: 3.0ms preprocess, 135.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 126.9ms\n",
      "Speed: 2.9ms preprocess, 126.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 137.2ms\n",
      "Speed: 2.8ms preprocess, 137.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 124.4ms\n",
      "Speed: 2.9ms preprocess, 124.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.7ms\n",
      "Speed: 2.8ms preprocess, 131.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 122.4ms\n",
      "Speed: 2.9ms preprocess, 122.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.8ms\n",
      "Speed: 2.9ms preprocess, 129.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 116.3ms\n",
      "Speed: 3.0ms preprocess, 116.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.5ms\n",
      "Speed: 2.9ms preprocess, 129.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 111.6ms\n",
      "Speed: 2.8ms preprocess, 111.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.6ms\n",
      "Speed: 2.7ms preprocess, 130.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 119.3ms\n",
      "Speed: 2.9ms preprocess, 119.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.8ms\n",
      "Speed: 2.9ms preprocess, 135.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 112.6ms\n",
      "Speed: 3.1ms preprocess, 112.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.9ms\n",
      "Speed: 2.8ms preprocess, 129.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 122.1ms\n",
      "Speed: 3.0ms preprocess, 122.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.6ms\n",
      "Speed: 3.3ms preprocess, 127.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 120.4ms\n",
      "Speed: 2.9ms preprocess, 120.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.5ms\n",
      "Speed: 2.8ms preprocess, 126.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 117.4ms\n",
      "Speed: 2.8ms preprocess, 117.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Face + Object Detection (YOLO + OpenCV)\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# ---------------- Load YOLO Models ----------------\n",
    "# YOLO for object detection\n",
    "object_model = YOLO(\"yolov8n.pt\")      # Detect objects (80 classes)\n",
    "\n",
    "# YOLO for face detection (trained face model)\n",
    "face_model = YOLO(\"yolov8n-face.pt\")   # Download automatically\n",
    "\n",
    "# ---------------- Open Webcam ----------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ------------ Object Detection --------------\n",
    "    object_results = object_model(frame, stream=True)\n",
    "\n",
    "    for r in object_results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            label = object_model.names[cls]\n",
    "\n",
    "            # Draw Object Box (Green)\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)),\n",
    "                          (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, f\"{label} {conf:.2f}\",\n",
    "                        (int(x1), int(y1) - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # ------------ Face Detection --------------\n",
    "    face_results = face_model(frame, stream=True)\n",
    "\n",
    "    for r in face_results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "\n",
    "            # Draw Face Box (Blue)\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)),\n",
    "                          (255, 0, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, \"Face\",\n",
    "                        (int(x1), int(y1) - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    # ------------- Show Output ------------------\n",
    "    cv2.imshow(\"Face + Object Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab3b20-7d52-42f2-9be4-df356726970e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (MediaPipe)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
