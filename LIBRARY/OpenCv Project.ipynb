{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980daa30-f7ea-4e8c-aba1-0c17a61abb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pywin32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0aaf8-0bbc-44d9-8260-9c81678349df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be16fa4-a2fa-49f0-9c61-2786b22d692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SpeechRecognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e31742-a2dc-47b3-a3b9-1ab662f1b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1e6da-1135-451a-be8b-b5770f855b97",
   "metadata": {},
   "source": [
    "# Face & Object Detection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f6b1c-125f-49df-bf51-3d2977b84610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Detect faces\n",
    "import cv2\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(gray,1.1,5) # detectMultiScale- scan and detect faces ,1.1 balance, not too slow,blind ,minNeighbors=5\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w , y+h),(0,255,0),2) # x=how far from left,y= how dar from top,w=width of face,h=height of face\n",
    "    cv2.imshow(\"Webcam face Detection\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018266bf-90a1-4673-bc97-b14e4f871cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face,Smile,Eye Detection\n",
    "import cv2\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade=cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "smile_cascade=cv2.CascadeClassifier(\"haarcascade_smile.xml\")\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(gray,1.1,5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w , y+h),(0,255,0),2)\n",
    "    roi_gray=gray[y:y+h,x:x+w] # roi=reseon of intrest [150:150+80 , 100:100+80]\n",
    "    roi_color=frame[y:y+h,x:x+w]\n",
    "    eye=eye_cascade.detectMultiScale(roi_gray,1.1,10)\n",
    "    if len(eye)>0:\n",
    "        cv2.putText(frame,\"Eye Detected\",(x,y-40),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,0),1)\n",
    "    smile=smile_cascade.detectMultiScale(roi_gray,1.7,20)\n",
    "    if len(smile)>0:\n",
    "        cv2.putText(frame,\"Smile Detected\",(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,0),1)\n",
    "    if len(faces)>0:\n",
    "        cv2.putText(frame,\"Face Detected\",(x,y-20),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,0),1)\n",
    "    cv2.imshow(\"Smart Face Detector\",frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5ac6fb-b0dd-461d-b39a-773cf8c17cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand Detection \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # ðŸ‘‰ Use flip(1) for mirror view without swapping left/right\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks, hand_label in zip(result.multi_hand_landmarks, result.multi_handedness):\n",
    "                # extract left/right from mp result\n",
    "                label = hand_label.classification[0].label  # \"Left\" or \"Right\"\n",
    "                # Draw hand landmarks\n",
    "                mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                # Show label on screen\n",
    "                cv2.putText(frame, label + \" Hand\",(10, 70), cv2.FONT_HERSHEY_SIMPLEX,1, (0, 255, 0), 1)\n",
    "        cv2.imshow(\"Hand Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d6e6f-b94a-459d-9114-35cf60e9c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finger Counting Using Webcam\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1,min_detection_confidence=0.7,min_tracking_confidence=0.7)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "tip_ids = [4, 8, 12, 16, 20]\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, c = frame.shape\n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(imgRGB)\n",
    "    if result.multi_hand_landmarks:\n",
    "        handLms = result.multi_hand_landmarks[0]\n",
    "        lm_list = []\n",
    "        # Get hand type (Left/Right)\n",
    "        hand_type = result.multi_handedness[0].classification[0].label\n",
    "        for id, lm in enumerate(handLms.landmark):\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            lm_list.append((cx, cy))\n",
    "            fingers = []\n",
    "        # --------------------- Thumb Logic ----------------------\n",
    "        if hand_type == \"Right\":\n",
    "            # For right hand (mirror flip)\n",
    "            if lm_list[4][0] > lm_list[3][0]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "        else:  # Left Hand\n",
    "            if lm_list[4][0] < lm_list[3][0]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "        # --------------------- Other 4 Fingers ----------------------\n",
    "        for i in range(1, 5):\n",
    "            if lm_list[tip_ids[i]][1] < lm_list[tip_ids[i] - 2][1]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "        total = fingers.count(1)\n",
    "        # Draw count box\n",
    "        cv2.rectangle(frame, (20, 20), (200, 150), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f\"{total}\", (70, 120),cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 5)\n",
    "        # Show hand type\n",
    "        cv2.putText(frame, hand_type, (20, 180),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "        mp_draw.draw_landmarks(frame, handLms, mp_hands.HAND_CONNECTIONS)\n",
    "    cv2.imshow(\"Finger Counter\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b526bf2-aa24-4551-9d65-6accb503eee3",
   "metadata": {},
   "source": [
    "# PC Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c3bfe7-cfd7-44f5-970e-34ca89f1ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valume controlar by Hand\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "\n",
    "# ---------------------- Volume Setup (OLD + WORKING METHOD) ------------------------\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "vol_range = volume.GetVolumeRange()\n",
    "min_vol = vol_range[0]\n",
    "max_vol = vol_range[1]\n",
    "\n",
    "# ---------------------- Mediapipe Hands ------------------------\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(imgRGB)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for handLMs in result.multi_hand_landmarks:\n",
    "            lm_list = []\n",
    "            for id, lm in enumerate(handLMs.landmark):\n",
    "                h, w, c = frame.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                lm_list.append((cx, cy))\n",
    "\n",
    "            x1, y1 = lm_list[4]   # thumb tip\n",
    "            x2, y2 = lm_list[8]   # index tip\n",
    "\n",
    "            length = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "            # Map distance to volume\n",
    "            vol = int((length - 20) / (200 - 20) * (max_vol - min_vol) + min_vol)\n",
    "            vol = max(min(vol, max_vol), min_vol)\n",
    "            volume.SetMasterVolumeLevel(vol, None)\n",
    "\n",
    "            cv2.circle(frame, (x1, y1), 10, (255, 0, 255), -1)\n",
    "            cv2.circle(frame, (x2, y2), 10, (255, 0, 255), -1)\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Show Volume %\n",
    "            percentage = int((vol - min_vol) / (max_vol - min_vol) * 100)\n",
    "            cv2.putText(frame, f\"Volume: {percentage}%\", (40, 70),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Volume Gesture Control\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e1a36-ef44-4194-9014-f44d1ce0e0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8e23be-7305-4ec7-a588-f1821f34eea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting... Press ESC to exit\n"
     ]
    }
   ],
   "source": [
    "# Hand Gesture + Voice Command + Voice Typing (toggle) PC Controller with HUD\n",
    "# Mixed Mode with extended gesture set (Drag, swipes, media, system gestures, etc.)\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import math\n",
    "import threading\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import os\n",
    "import webbrowser\n",
    "import subprocess\n",
    "import shutil\n",
    "import ctypes\n",
    "\n",
    "# -----------------------\n",
    "# Configuration & setup\n",
    "# -----------------------\n",
    "pyautogui.FAILSAFE = False\n",
    "SCREEN_W, SCREEN_H = pyautogui.size()\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands_detector = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.6, min_tracking_confidence=0.5)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# HUD state\n",
    "hud_text = \"\"\n",
    "hud_icon = None\n",
    "hud_timer = 0\n",
    "HUD_SHOW_TIME = 1.2\n",
    "\n",
    "# Gesture state / debouncing\n",
    "dragging = False\n",
    "drag_start = None\n",
    "last_click_time = 0\n",
    "voice_typing_enabled = False\n",
    "\n",
    "# New gesture state variables\n",
    "prev_palm = None\n",
    "prev_time = time.time()\n",
    "last_gesture_times = {}\n",
    "gesture_cooldown = 0.8  # seconds between same gesture\n",
    "shake_buffer = []\n",
    "sequence_buffer = []\n",
    "sequence_time = None\n",
    "\n",
    "# TTS\n",
    "tts_engine = pyttsx3.init()\n",
    "def speak(text):\n",
    "    try:\n",
    "        tts_engine.say(text)\n",
    "        tts_engine.runAndWait()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# -----------------------\n",
    "# HUD Helper\n",
    "# -----------------------\n",
    "def set_hud(text, icon=None):\n",
    "    global hud_text, hud_icon, hud_timer\n",
    "    hud_text = text\n",
    "    hud_icon = icon\n",
    "    hud_timer = time.time()\n",
    "\n",
    "# -----------------------\n",
    "# Utilities (apps / web / brightness / system)\n",
    "# -----------------------\n",
    "def safe_start_command(cmd_list, friendly_name=None):\n",
    "    try:\n",
    "        subprocess.Popen(cmd_list, shell=False)\n",
    "        set_hud(f\"Opened {friendly_name or cmd_list[0]}\", \"open\")\n",
    "        speak(f\"Opening {friendly_name or cmd_list[0]}\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        try:\n",
    "            os.system(\" \".join(cmd_list))\n",
    "            set_hud(f\"Opened {friendly_name or cmd_list[0]}\", \"open\")\n",
    "            speak(f\"Opening {friendly_name or cmd_list[0]}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            set_hud(f\"Cannot open {friendly_name or cmd_list[0]}\", \"error\")\n",
    "            speak(f\"Failed to open {friendly_name or cmd_list[0]}\")\n",
    "            return False\n",
    "\n",
    "def open_url(url, friendly_name=None):\n",
    "    try:\n",
    "        webbrowser.open(url, new=2)\n",
    "        set_hud(f\"Opened {friendly_name or url}\", \"web\")\n",
    "        speak(f\"Opening {friendly_name or url}\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        set_hud(f\"Cannot open {friendly_name or url}\", \"error\")\n",
    "        speak(f\"Failed to open {friendly_name or url}\")\n",
    "        return False\n",
    "\n",
    "def open_windows_uri(uri, friendly_name=None):\n",
    "    try:\n",
    "        os.system(f\"start {uri}\")\n",
    "        set_hud(f\"Opened {friendly_name or uri}\", \"app\")\n",
    "        speak(f\"Opening {friendly_name or uri}\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        set_hud(f\"Cannot open {friendly_name or uri}\", \"error\")\n",
    "        speak(f\"Failed to open {friendly_name or uri}\")\n",
    "        return False\n",
    "\n",
    "# -----------------------\n",
    "# Active window helper (Windows)\n",
    "# -----------------------\n",
    "def get_active_window_title():\n",
    "    \"\"\"Return the active window title (Windows). Empty string on failure.\"\"\"\n",
    "    try:\n",
    "        user32 = ctypes.windll.user32\n",
    "        kernel32 = ctypes.windll.kernel32\n",
    "        h_wnd = user32.GetForegroundWindow()\n",
    "        length = user32.GetWindowTextLengthW(h_wnd)\n",
    "        buff = ctypes.create_unicode_buffer(length + 1)\n",
    "        user32.GetWindowTextW(h_wnd, buff, length + 1)\n",
    "        return buff.value.lower()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "# -----------------------\n",
    "# Close app helper\n",
    "# -----------------------\n",
    "CLOSE_MAP = {\n",
    "    \"chrome\": \"chrome.exe\",\n",
    "    \"google chrome\": \"chrome.exe\",\n",
    "    \"edge\": \"msedge.exe\",\n",
    "    \"firefox\": \"firefox.exe\",\n",
    "    \"brave\": \"brave.exe\",\n",
    "    \"whatsapp\": \"WhatsApp.exe\",\n",
    "    \"whatsapp web\": \"chrome.exe\",\n",
    "    \"youtube\": \"chrome.exe\",\n",
    "    \"spotify\": \"spotify.exe\",\n",
    "    \"vscode\": \"Code.exe\",\n",
    "    \"vs code\": \"Code.exe\",\n",
    "    \"notepad\": \"notepad.exe\",\n",
    "    \"calculator\": \"Calculator.exe\",\n",
    "    \"cmd\": \"cmd.exe\",\n",
    "    \"netflix\": \"chrome.exe\",\n",
    "    \"instagram\": \"chrome.exe\",\n",
    "    \"facebook\": \"chrome.exe\",\n",
    "    \"github\": \"chrome.exe\",\n",
    "}\n",
    "\n",
    "def close_app_by_name(name):\n",
    "    \"\"\"Try to close app: attempt Alt+F4 if active window matches; else taskkill process.\"\"\"\n",
    "    name_l = name.lower().strip()\n",
    "    title = get_active_window_title()\n",
    "    # If the active window title contains the app name, send Alt+F4\n",
    "    if name_l in title or any(k in title for k in [name_l, name_l.replace(\" \", \"\")]):\n",
    "        try:\n",
    "            pyautogui.hotkey('alt', 'f4')\n",
    "            set_hud(f\"Closed {name}\", \"close\")\n",
    "            speak(f\"Closed {name}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    # fallback: taskkill with mapped exe\n",
    "    proc = CLOSE_MAP.get(name_l)\n",
    "    if proc:\n",
    "        try:\n",
    "            subprocess.run(['taskkill', '/IM', proc, '/F'], check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "            set_hud(f\"Killed {proc}\", \"close\")\n",
    "            speak(f\"Closed {name}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            set_hud(f\"Failed to close {name}\", \"error\")\n",
    "            speak(f\"Failed to close {name}\")\n",
    "            return False\n",
    "    else:\n",
    "        # unknown name fallback: attempt taskkill by partial match or Alt+F4\n",
    "        try:\n",
    "            pyautogui.hotkey('alt', 'f4')\n",
    "            set_hud(f\"Attempted close {name}\", \"close\")\n",
    "            speak(f\"Attempted to close {name}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            set_hud(f\"Close failed {name}\", \"error\")\n",
    "            speak(f\"Close failed for {name}\")\n",
    "            return False\n",
    "\n",
    "# -----------------------\n",
    "# Minimal brightness helpers (best-effort)\n",
    "# -----------------------\n",
    "def get_brightness_windows():\n",
    "    try:\n",
    "        out = subprocess.check_output(['powershell', '-Command', \"(Get-WmiObject -Namespace root/WMI -Class WmiMonitorBrightness).CurrentBrightness\"], stderr=subprocess.DEVNULL, universal_newlines=True)\n",
    "        lines = [l.strip() for l in out.splitlines() if l.strip().isdigit()]\n",
    "        if lines:\n",
    "            return int(lines[-1])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def set_brightness_windows(value):\n",
    "    try:\n",
    "        value = max(0, min(100, int(value)))\n",
    "        cmd = ['powershell', '-Command', \"(Get-WmiObject -Namespace root/WMI -Class WmiMonitorBrightnessMethods).WmiSetBrightness(1,{})\".format(value)]\n",
    "        subprocess.check_output(cmd, stderr=subprocess.DEVNULL)\n",
    "        set_hud(f\"Brightness {value}%\", \"brightness\")\n",
    "        speak(f\"Brightness set to {value} percent\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        set_hud(\"Brightness control not supported\", \"brightness\")\n",
    "        speak(\"Brightness control not supported on this PC\")\n",
    "        return False\n",
    "\n",
    "def change_brightness(delta):\n",
    "    cur = get_brightness_windows()\n",
    "    if cur is None:\n",
    "        set_hud(\"Bright control unavailable\", \"brightness\")\n",
    "        speak(\"Cannot control brightness\")\n",
    "        return False\n",
    "    new = max(0, min(100, cur + delta))\n",
    "    return set_brightness_windows(new)\n",
    "\n",
    "def show_battery_percentage():\n",
    "    try:\n",
    "        out = subprocess.check_output(['wmic', 'Path', 'Win32_Battery', 'Get', 'EstimatedChargeRemaining'], stderr=subprocess.DEVNULL, universal_newlines=True)\n",
    "        lines = [l.strip() for l in out.splitlines() if l.strip().isdigit()]\n",
    "        if lines:\n",
    "            pct = lines[-1]\n",
    "            set_hud(f\"Battery: {pct}%\", \"battery\")\n",
    "            speak(f\"Battery is {pct} percent\")\n",
    "            return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    set_hud(\"Battery info unavailable\", \"battery\")\n",
    "    speak(\"Battery information is not available\")\n",
    "    return False\n",
    "\n",
    "# -----------------------\n",
    "# Actions (same mapping as before)\n",
    "# -----------------------\n",
    "def execute_action(action):\n",
    "    set_hud(f\"{action}\", icon=action)\n",
    "    speak(action.replace(\"_\", \" \"))\n",
    "\n",
    "    try:\n",
    "        # Browser\n",
    "        if action == \"open_whatsapp\": return open_url(\"https://web.whatsapp.com\", \"WhatsApp Web\")\n",
    "        if action == \"open_youtube\": return open_url(\"https://www.youtube.com\", \"YouTube\")\n",
    "        if action == \"open_instagram\": return open_url(\"https://www.instagram.com\", \"Instagram\")\n",
    "        if action == \"open_facebook\": return open_url(\"https://www.facebook.com\", \"Facebook\")\n",
    "        if action == \"open_google\": return open_url(\"https://www.google.com\", \"Google\")\n",
    "        if action == \"open_gmail\": return open_url(\"https://mail.google.com\", \"Gmail\")\n",
    "        if action == \"open_netflix\": return open_url(\"https://www.netflix.com\", \"Netflix\")\n",
    "        if action == \"open_github\": return open_url(\"https://github.com\", \"GitHub\")\n",
    "        if action == \"open_maps\": return open_url(\"https://maps.google.com\", \"Google Maps\")\n",
    "\n",
    "        # Apps\n",
    "        if action == \"open_calculator\": return safe_start_command([\"calc\"], \"Calculator\")\n",
    "        if action == \"open_notepad\": return safe_start_command([\"notepad\"], \"Notepad\")\n",
    "        if action == \"open_cmd\": return safe_start_command([\"cmd\"], \"Command Prompt\")\n",
    "        if action == \"open_vs_code\":\n",
    "            if shutil.which(\"code\"): return safe_start_command([\"code\"], \"VS Code\")\n",
    "            possible = [r\"C:\\Users\\%USERNAME%\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe\", r\"C:\\Program Files\\Microsoft VS Code\\Code.exe\"]\n",
    "            for p in possible:\n",
    "                p = os.path.expandvars(p)\n",
    "                if os.path.exists(p): return safe_start_command([p], \"VS Code\")\n",
    "            set_hud(\"VS Code not found\", \"error\"); speak(\"Visual Studio Code not found\"); return False\n",
    "        if action == \"open_spotify\":\n",
    "            try:\n",
    "                return open_windows_uri(\"spotify:\")\n",
    "            except Exception:\n",
    "                if shutil.which(\"spotify\"): return safe_start_command([\"spotify\"], \"Spotify\")\n",
    "                set_hud(\"Spotify not found\", \"error\"); speak(\"Spotify not found\"); return False\n",
    "        if action == \"open_camera\": return open_windows_uri(\"microsoft.windows.camera:\", \"Camera\")\n",
    "        if action == \"open_settings\": return open_windows_uri(\"ms-settings:\", \"Settings\")\n",
    "        if action == \"open_task_manager\": return safe_start_command([\"taskmgr\"], \"Task Manager\")\n",
    "\n",
    "        # Media controls\n",
    "        if action == \"play_pause\": pyautogui.press(\"playpause\"); set_hud(\"Play/Pause\", \"play\"); return True\n",
    "        if action == \"next_track\": pyautogui.press(\"nexttrack\"); set_hud(\"Next Track\", \"next\"); return True\n",
    "        if action == \"prev_track\": pyautogui.press(\"prevtrack\"); set_hud(\"Previous Track\", \"prev\"); return True\n",
    "\n",
    "        # Volume\n",
    "        if action == \"volume_up\": pyautogui.press(\"volumeup\"); return True\n",
    "        if action == \"volume_down\": pyautogui.press(\"volumedown\"); return True\n",
    "        if action == \"mute\": pyautogui.press(\"volumemute\"); return True\n",
    "\n",
    "        # Brightness\n",
    "        if action == \"brightness_up\": return change_brightness(10)\n",
    "        if action == \"brightness_down\": return change_brightness(-10)\n",
    "\n",
    "        # System\n",
    "        if action == \"shutdown\": os.system(\"shutdown /s /t 10\"); return True\n",
    "        if action == \"restart\": os.system(\"shutdown /r /t 5\"); return True\n",
    "        if action == \"sleep\":\n",
    "            try:\n",
    "                os.system(\"rundll32.exe powrprof.dll,SetSuspendState 0,1,0\"); return True\n",
    "            except Exception:\n",
    "                set_hud(\"Sleep failed\", \"error\"); speak(\"Failed to enter sleep\"); return False\n",
    "        if action == \"lock\": os.system(\"rundll32.exe user32.dll,LockWorkStation\"); return True\n",
    "        if action == \"show_time\":\n",
    "            import datetime\n",
    "            now = datetime.datetime.now().strftime(\"%I:%M %p\")\n",
    "            set_hud(f\"Time: {now}\", \"time\"); speak(f\"The time is {now}\"); return True\n",
    "        if action == \"battery_status\": return show_battery_percentage()\n",
    "\n",
    "    except Exception as e:\n",
    "        set_hud(f\"Error: {e}\", \"error\")\n",
    "        speak(\"An error occurred\")\n",
    "        return False\n",
    "\n",
    "    set_hud(\"Unknown action\", \"error\"); speak(\"Unknown action\"); return False\n",
    "\n",
    "# -----------------------\n",
    "# SEARCH: app-aware typing into current focus\n",
    "# -----------------------\n",
    "def perform_search_query(query):\n",
    "    \"\"\"Type/search based on active window context.\"\"\"\n",
    "    if not query:\n",
    "        return False\n",
    "    title = get_active_window_title()\n",
    "    # prioritize YouTube specific behavior\n",
    "    if 'youtube' in title:\n",
    "        # press '/' to focus YouTube search, then type\n",
    "        try:\n",
    "            pyautogui.press('/')\n",
    "            time.sleep(0.2)\n",
    "            pyautogui.typewrite(query, interval=0.02)\n",
    "            pyautogui.press('enter')\n",
    "            set_hud(f\"YT Search: {query}\", \"search\")\n",
    "            speak(f\"Searching YouTube for {query}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    # VS Code / Visual Studio\n",
    "    if 'visual studio code' in title or 'vs code' in title or 'code -' in title:\n",
    "        try:\n",
    "            pyautogui.hotkey('ctrl', 'f')\n",
    "            time.sleep(0.15)\n",
    "            pyautogui.typewrite(query, interval=0.02)\n",
    "            set_hud(f\"VSCode Search: {query}\", \"search\")\n",
    "            speak(f\"Searching in VS Code for {query}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Notepad\n",
    "    if 'notepad' in title:\n",
    "        try:\n",
    "            pyautogui.hotkey('ctrl', 'f')\n",
    "            time.sleep(0.15)\n",
    "            pyautogui.typewrite(query, interval=0.02)\n",
    "            pyautogui.press('enter')\n",
    "            set_hud(f\"Notepad Search: {query}\", \"search\")\n",
    "            speak(f\"Searching in notepad for {query}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    # WhatsApp Desktop or WhatsApp Web\n",
    "    if 'whatsapp' in title:\n",
    "        try:\n",
    "            # WhatsApp desktop: Ctrl+F focuses search; web also works with Ctrl+F\n",
    "            pyautogui.hotkey('ctrl', 'f')\n",
    "            time.sleep(0.15)\n",
    "            pyautogui.typewrite(query, interval=0.02)\n",
    "            pyautogui.press('enter')\n",
    "            set_hud(f\"WhatsApp Search: {query}\", \"search\")\n",
    "            speak(f\"Searching in WhatsApp for {query}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Browser general fallback: focus address/search bar (Ctrl+L) and search (or type into search box)\n",
    "    if any(b in title for b in ['chrome', 'edge', 'firefox', 'brave', 'msedge', 'mozilla']):\n",
    "        try:\n",
    "            pyautogui.hotkey('ctrl', 'l')\n",
    "            time.sleep(0.12)\n",
    "            # use google search in address bar\n",
    "            url = f\"https://www.google.com/search?q={query.replace(' ', '+')}\"\n",
    "            pyautogui.typewrite(url, interval=0.02)\n",
    "            pyautogui.press('enter')\n",
    "            set_hud(f\"Web Search: {query}\", \"search\")\n",
    "            speak(f\"Searching web for {query}\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Generic fallback: just type where cursor is and press Enter\n",
    "    try:\n",
    "        pyautogui.typewrite(query, interval=0.02)\n",
    "        pyautogui.press('enter')\n",
    "        set_hud(f\"Typed: {query}\", \"type\")\n",
    "        speak(f\"Searching for {query}\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        set_hud(\"Search failed\", \"error\")\n",
    "        speak(\"Search failed\")\n",
    "        return False\n",
    "\n",
    "# -----------------------\n",
    "# Voice listener (extended: search + close commands)\n",
    "# -----------------------\n",
    "def voice_listener():\n",
    "    global voice_typing_enabled\n",
    "    r = sr.Recognizer()\n",
    "    try:\n",
    "        mic = sr.Microphone()\n",
    "    except Exception:\n",
    "        set_hud(\"Microphone not found\", icon=\"mic_error\")\n",
    "        return\n",
    "\n",
    "    with mic as source:\n",
    "        r.adjust_for_ambient_noise(source, duration=1)\n",
    "\n",
    "    set_hud(\"Voice Ready\", \"mic\")\n",
    "    speak(\"Voice ready\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            with mic as source:\n",
    "                audio = r.listen(source, phrase_time_limit=5)\n",
    "            try:\n",
    "                text = r.recognize_google(audio).lower().strip()\n",
    "            except sr.UnknownValueError:\n",
    "                continue\n",
    "            except sr.RequestError:\n",
    "                set_hud(\"Speech Service Error\", \"mic_error\")\n",
    "                time.sleep(2); continue\n",
    "\n",
    "            set_hud(f\"Voice: {text}\", \"voice\")\n",
    "\n",
    "            # enable/disable voice typing first\n",
    "            if \"disable voice typing\" in text:\n",
    "                voice_typing_enabled = False; set_hud(\"Voice Typing OFF\", \"type_off\"); speak(\"Voice typing disabled\"); continue\n",
    "            if \"enable voice typing\" in text:\n",
    "                voice_typing_enabled = True; set_hud(\"Voice Typing ON\", \"type_on\"); speak(\"Voice typing enabled\"); continue\n",
    "\n",
    "            # If voice typing is on, type everything else (but still allow some commands)\n",
    "            if voice_typing_enabled:\n",
    "                # allow \"search ...\" while in typing mode: treat specially\n",
    "                if text.startswith(\"search \"):\n",
    "                    query = text.replace(\"search\", \"\", 1).strip()\n",
    "                    perform_search_query(query)\n",
    "                    continue\n",
    "                # allow \"close ...\" in typing mode too\n",
    "                if text.startswith(\"close \"):\n",
    "                    name = text.replace(\"close\", \"\", 1).strip()\n",
    "                    close_app_by_name(name)\n",
    "                    continue\n",
    "                # otherwise type the text\n",
    "                set_hud(\"Typing...\", \"type\"); pyautogui.typewrite(text + \" \", interval=0.02); continue\n",
    "\n",
    "            # -------------------------\n",
    "            # SEARCH (not typing mode)\n",
    "            # -------------------------\n",
    "            if text.startswith(\"search \"):\n",
    "                query = text.replace(\"search\", \"\", 1).strip()\n",
    "                if query:\n",
    "                    perform_search_query(query)\n",
    "                    continue\n",
    "\n",
    "            # -------------------------\n",
    "            # CLOSE APP COMMANDS\n",
    "            # -------------------------\n",
    "            if text.startswith(\"close \"):\n",
    "                name = text.replace(\"close\", \"\", 1).strip()\n",
    "                close_app_by_name(name)\n",
    "                continue\n",
    "\n",
    "            # -------------------------\n",
    "            # OTHER COMMANDS (unchanged)\n",
    "            # -------------------------\n",
    "            if \"open whatsapp\" in text: execute_action(\"open_whatsapp\"); continue\n",
    "            if \"open youtube\" in text: execute_action(\"open_youtube\"); continue\n",
    "            if \"open instagram\" in text: execute_action(\"open_instagram\"); continue\n",
    "            if \"open facebook\" in text: execute_action(\"open_facebook\"); continue\n",
    "            if \"open google\" in text: execute_action(\"open_google\"); continue\n",
    "            if \"open gmail\" in text: execute_action(\"open_gmail\"); continue\n",
    "            if \"open netflix\" in text: execute_action(\"open_netflix\"); continue\n",
    "            if \"open github\" in text: execute_action(\"open_github\"); continue\n",
    "            if \"open maps\" in text or \"open google maps\" in text: execute_action(\"open_maps\"); continue\n",
    "            if \"open calculator\" in text: execute_action(\"open_calculator\"); continue\n",
    "            if \"open notepad\" in text: execute_action(\"open_notepad\"); continue\n",
    "            if \"open command prompt\" in text or \"open cmd\" in text: execute_action(\"open_cmd\"); continue\n",
    "            if \"open vs code\" in text or \"open vscode\" in text or \"open visual studio code\" in text: execute_action(\"open_vs_code\"); continue\n",
    "            if \"open spotify\" in text: execute_action(\"open_spotify\"); continue\n",
    "            if \"open camera\" in text: execute_action(\"open_camera\"); continue\n",
    "            if \"open settings\" in text: execute_action(\"open_settings\"); continue\n",
    "            if \"open task manager\" in text or \"task manager\" in text: execute_action(\"open_task_manager\"); continue\n",
    "            if \"volume up\" in text or \"increase volume\" in text: execute_action(\"volume_up\"); continue\n",
    "            if \"volume down\" in text or \"decrease volume\" in text: execute_action(\"volume_down\"); continue\n",
    "            if \"mute\" in text: execute_action(\"mute\"); continue\n",
    "            if \"play\" in text or \"pause\" in text or \"play pause\" in text: execute_action(\"play_pause\"); continue\n",
    "            if \"next\" in text or \"next song\" in text: execute_action(\"next_track\"); continue\n",
    "            if \"previous\" in text or \"prev\" in text: execute_action(\"prev_track\"); continue\n",
    "            if \"increase brightness\" in text or \"brightness up\" in text: execute_action(\"brightness_up\"); continue\n",
    "            if \"decrease brightness\" in text or \"brightness down\" in text: execute_action(\"brightness_down\"); continue\n",
    "            if \"shutdown\" in text: execute_action(\"shutdown\"); continue\n",
    "            if \"restart\" in text: execute_action(\"restart\"); continue\n",
    "            if \"sleep\" in text or \"hibernate\" in text: execute_action(\"sleep\"); continue\n",
    "            if \"lock\" in text: execute_action(\"lock\"); continue\n",
    "            if \"what time\" in text or \"tell me the time\" in text: execute_action(\"show_time\"); continue\n",
    "            if \"battery\" in text or \"battery percentage\" in text or \"show battery\" in text: execute_action(\"battery_status\"); continue\n",
    "\n",
    "        except Exception:\n",
    "            time.sleep(0.2)\n",
    "\n",
    "# Start voice thread\n",
    "voice_thread = threading.Thread(target=voice_listener, daemon=True)\n",
    "voice_thread.start()\n",
    "\n",
    "# -----------------------\n",
    "# HUD Drawer\n",
    "# -----------------------\n",
    "def draw_hud(frame):\n",
    "    if time.time() - hud_timer > HUD_SHOW_TIME:\n",
    "        return frame\n",
    "    h, w, _ = frame.shape\n",
    "    overlay = frame.copy()\n",
    "    x0, y0 = 10, h - 80\n",
    "    cv2.rectangle(overlay, (x0, y0), (x0 + 420, y0 + 60), (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay, 0.55, frame, 0.45, 0, frame)\n",
    "    if hud_icon:\n",
    "        cv2.circle(frame, (x0 + 40, y0 + 30), 20, (255, 180, 100), -1)\n",
    "        cv2.putText(frame, hud_icon[:10], (x0 + 10, y0 + 55),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (220, 220, 220), 1)\n",
    "    cv2.putText(frame, hud_text, (x0 + 80, y0 + 35),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    return frame\n",
    "\n",
    "# -----------------------\n",
    "# Helpers for gestures\n",
    "# -----------------------\n",
    "def distance(p1, p2):\n",
    "    return int(math.dist(p1, p2))\n",
    "\n",
    "def fingers_up(hand_landmarks):\n",
    "    # returns dict of finger name -> bool (True if extended)\n",
    "    tips = {'thumb':4, 'index':8, 'middle':12, 'ring':16, 'pinky':20}\n",
    "    res = {}\n",
    "    # For fingers (except thumb) compare tip y w.r.t pip y\n",
    "    for f in ['index','middle','ring','pinky']:\n",
    "        tip = hand_landmarks.landmark[tips[f]]\n",
    "        pip = hand_landmarks.landmark[tips[f]-2]\n",
    "        res[f] = tip.y < pip.y  # lower y means higher on image\n",
    "    # Thumb: compare tip x to ip (handedness not used; we assume mirrored feed)\n",
    "    thumb_tip = hand_landmarks.landmark[tips['thumb']]\n",
    "    thumb_ip = hand_landmarks.landmark[3]\n",
    "    # thumb extended if tip x is to the left of ip (mirrored frame)\n",
    "    res['thumb'] = thumb_tip.x < thumb_ip.x\n",
    "    return res\n",
    "\n",
    "def palm_center(hand_landmarks, frame_w, frame_h):\n",
    "    # approximate center using wrist(0) and middle_finger_mcp(9)\n",
    "    w = hand_landmarks.landmark[0]\n",
    "    m = hand_landmarks.landmark[9]\n",
    "    cx = int(((w.x + m.x)/2) * frame_w)\n",
    "    cy = int(((w.y + m.y)/2) * frame_h)\n",
    "    return (cx, cy)\n",
    "\n",
    "def time_since(name):\n",
    "    return time.time() - last_gesture_times.get(name, 0)\n",
    "\n",
    "def set_gtime(name):\n",
    "    last_gesture_times[name] = time.time()\n",
    "\n",
    "# -----------------------\n",
    "# MAIN HAND GESTURE LOOP (extended)\n",
    "# -----------------------\n",
    "print(\"Starting... Press ESC to exit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands_detector.process(rgb)\n",
    "\n",
    "    current_time = time.time()\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # coordinates (pixel)\n",
    "        coords = [(int(lm.x * w), int(lm.y * h)) for lm in hand_landmarks.landmark]\n",
    "        index = coords[8]\n",
    "        thumb = coords[4]\n",
    "        middle = coords[12]\n",
    "        pinky = coords[20]\n",
    "        ring = coords[16]\n",
    "\n",
    "        # move mouse by index finger\n",
    "        try:\n",
    "            screen_x = int(hand_landmarks.landmark[8].x * SCREEN_W)\n",
    "            screen_y = int(hand_landmarks.landmark[8].y * SCREEN_H)\n",
    "            pyautogui.moveTo(screen_x, screen_y, duration=0.03)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # simple pinch distances\n",
    "        pinch = distance(index, thumb)\n",
    "        pinky_touch = distance(pinky, thumb)\n",
    "        ring_pinch = distance(coords[16], thumb)\n",
    "\n",
    "        # fingers up\n",
    "        fup = fingers_up(hand_landmarks)\n",
    "\n",
    "        # palm center velocity for swipes\n",
    "        palm = palm_center(hand_landmarks, w, h)\n",
    "        if prev_palm is None:\n",
    "            prev_palm = palm\n",
    "            prev_time = current_time\n",
    "\n",
    "        dx = palm[0] - prev_palm[0]\n",
    "        dy = palm[1] - prev_palm[1]\n",
    "        dt = max(0.001, current_time - prev_time)\n",
    "        vx = dx / dt\n",
    "        vy = dy / dt\n",
    "\n",
    "        # --- Drag Mode (index+thumb pinch & move) ---\n",
    "        if pinch < 35:\n",
    "            # start dragging if not already\n",
    "            if not dragging and time_since(\"drag\") > gesture_cooldown:\n",
    "                dragging = True\n",
    "                drag_start = (screen_x, screen_y)\n",
    "                set_hud(\"Drag Mode ON\", \"drag\")\n",
    "                set_gtime(\"drag\")\n",
    "            # hold left mouse while dragging\n",
    "            try:\n",
    "                pyautogui.mouseDown()\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            if dragging:\n",
    "                try:\n",
    "                    pyautogui.mouseUp()\n",
    "                except Exception:\n",
    "                    pass\n",
    "                dragging = False\n",
    "                set_hud(\"Drag Mode OFF\", \"drag\")\n",
    "                set_gtime(\"drag_end\")\n",
    "\n",
    "        # --- Left Click / Double Click (quick pinch) ---\n",
    "        now = current_time\n",
    "        if pinch < 35 and time_since(\"pinch_click\") > 0.5:\n",
    "            set_gtime(\"pinch_click\")\n",
    "        if pinch >= 35 and time_since(\"pinch_click\") < 0.6 and time_since(\"pinch_release\") > 0.5:\n",
    "            if time_since(\"pinch_click\") < 0.5:\n",
    "                if now - last_click_time < 0.35:\n",
    "                    pyautogui.doubleClick(); set_hud(\"Double Click\", \"dbl\")\n",
    "                else:\n",
    "                    pyautogui.click(); set_hud(\"Left Click\", \"click\")\n",
    "                last_click_time = now\n",
    "            set_gtime(\"pinch_release\")\n",
    "\n",
    "        # --- Right-click hold (pinky+thumb pinch) ---\n",
    "        if pinky_touch < 40 and time_since(\"rightclick\") > gesture_cooldown:\n",
    "            pyautogui.rightClick()\n",
    "            set_hud(\"Right Click\", \"rclick\")\n",
    "            set_gtime(\"rightclick\")\n",
    "\n",
    "        # --- Middle click (ring pinch) ---\n",
    "        if ring_pinch < 35 and time_since(\"middleclick\") > gesture_cooldown:\n",
    "            pyautogui.middleClick()\n",
    "            set_hud(\"Middle Click\", \"mclick\")\n",
    "            set_gtime(\"middleclick\")\n",
    "\n",
    "        # --- Scroll Up / Down via open palm / fist (existing) ---\n",
    "        if (hand_landmarks.landmark[8].y < hand_landmarks.landmark[6].y and\n",
    "            hand_landmarks.landmark[12].y < hand_landmarks.landmark[10].y and\n",
    "            hand_landmarks.landmark[16].y < hand_landmarks.landmark[14].y and\n",
    "            hand_landmarks.landmark[20].y < hand_landmarks.landmark[18].y):\n",
    "            if time_since(\"scroll\") > 0.25:\n",
    "                pyautogui.scroll(80)\n",
    "                set_hud(\"Scroll Up\", \"up\")\n",
    "                set_gtime(\"scroll\")\n",
    "\n",
    "        if (hand_landmarks.landmark[8].y > hand_landmarks.landmark[6].y and\n",
    "            hand_landmarks.landmark[12].y > hand_landmarks.landmark[10].y and\n",
    "            hand_landmarks.landmark[16].y > hand_landmarks.landmark[14].y):\n",
    "            if time_since(\"scroll_down\") > 0.25:\n",
    "                pyautogui.scroll(-80)\n",
    "                set_hud(\"Scroll Down\", \"down\")\n",
    "                set_gtime(\"scroll_down\")\n",
    "\n",
    "        # --- Next / Prev Tab (index+middle up, ring down pattern) existing detection kept ---\n",
    "        if (hand_landmarks.landmark[8].y < hand_landmarks.landmark[6].y and\n",
    "            hand_landmarks.landmark[12].y < hand_landmarks.landmark[10].y and\n",
    "            hand_landmarks.landmark[16].y > hand_landmarks.landmark[14].y):\n",
    "            if time_since(\"next_tab\") > 0.6:\n",
    "                pyautogui.hotkey(\"ctrl\", \"tab\")\n",
    "                set_hud(\"Next Tab\", \"next\")\n",
    "                set_gtime(\"next_tab\")\n",
    "\n",
    "        if hand_landmarks.landmark[4].x < hand_landmarks.landmark[3].x:\n",
    "            if time_since(\"prev_tab\") > 0.6:\n",
    "                pyautogui.hotkey(\"ctrl\", \"shift\", \"tab\")\n",
    "                set_hud(\"Prev Tab\", \"prev\")\n",
    "                set_gtime(\"prev_tab\")\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # NEW: Gestures based on palm movement (swipes)\n",
    "        # ----------------------------------------------\n",
    "        # Swipe Right (fast palm vx > threshold) => Next Track / Forward\n",
    "        if vx > 1000 and abs(vx) > abs(vy):\n",
    "            if time_since(\"swipe_right\") > gesture_cooldown:\n",
    "                execute_action(\"next_track\")\n",
    "                set_gtime(\"swipe_right\")\n",
    "\n",
    "        # Swipe Left => Previous Track / Back\n",
    "        if vx < -1000 and abs(vx) > abs(vy):\n",
    "            if time_since(\"swipe_left\") > gesture_cooldown:\n",
    "                execute_action(\"prev_track\")\n",
    "                set_gtime(\"swipe_left\")\n",
    "\n",
    "        # Up motion while open palm => volume up (hand move up)\n",
    "        if vy < -500 and fup['index'] and fup['middle'] and fup['ring'] and fup['pinky']:\n",
    "            if time_since(\"palm_up\") > gesture_cooldown:\n",
    "                execute_action(\"volume_up\")\n",
    "                set_gtime(\"palm_up\")\n",
    "\n",
    "        # Down motion while open palm => volume down (hand move down)\n",
    "        if vy > 500 and fup['index'] and fup['middle'] and fup['ring'] and fup['pinky']:\n",
    "            if time_since(\"palm_down\") > gesture_cooldown:\n",
    "                execute_action(\"volume_down\")\n",
    "                set_gtime(\"palm_down\")\n",
    "\n",
    "        # --- Play/Pause: two-finger tap (index+middle tips quickly touch) ---\n",
    "        idx_mid_dist = distance(index, middle)\n",
    "        if idx_mid_dist < 30 and time_since(\"two_tap\") > 0.6:\n",
    "            execute_action(\"play_pause\")\n",
    "            set_gtime(\"two_tap\")\n",
    "\n",
    "        # --- Screenshot: \"L\" shape detection (index up, thumb away, others down) ---\n",
    "        if fup['index'] and not fup['middle'] and not fup['ring'] and not fup['pinky'] and fup['thumb'] and time_since(\"screenshot\") > 1.2:\n",
    "            try:\n",
    "                pyautogui.hotkey('win', 'shift', 's')\n",
    "                set_hud(\"Screenshot\", \"ss\")\n",
    "                speak(\"Screenshot captured\")\n",
    "            except Exception:\n",
    "                set_hud(\"Screenshot failed\", \"error\")\n",
    "            set_gtime(\"screenshot\")\n",
    "\n",
    "        # --- New Tab: quick open palm then close (detect palm open velocity change) ---\n",
    "        if fup['index'] and fup['middle'] and fup['ring'] and fup['pinky'] and fup['thumb'] and time_since(\"new_tab\") > 1.0:\n",
    "            if last_gesture_times.get(\"fist_time\") and (current_time - last_gesture_times[\"fist_time\"]) < 0.8:\n",
    "                pyautogui.hotkey(\"ctrl\", \"t\")\n",
    "                set_hud(\"New Tab\", \"newtab\")\n",
    "                set_gtime(\"new_tab\")\n",
    "\n",
    "        # --- Close Tab: fist + lateral shake (shake buffer) ---\n",
    "        is_fist = (not fup['index'] and not fup['middle'] and not fup['ring'] and not fup['pinky'])\n",
    "        if is_fist:\n",
    "            set_gtime(\"fist_time\")\n",
    "            shake_buffer.append(palm[0])\n",
    "            if len(shake_buffer) > 8:\n",
    "                shake_buffer.pop(0)\n",
    "            if len(shake_buffer) >= 6:\n",
    "                if (max(shake_buffer) - min(shake_buffer)) > 80 and time_since(\"close_tab\") > 1.2:\n",
    "                    pyautogui.hotkey(\"ctrl\", \"w\")\n",
    "                    set_hud(\"Close Tab\", \"ctab\")\n",
    "                    set_gtime(\"close_tab\")\n",
    "                    shake_buffer = []\n",
    "        else:\n",
    "            if len(shake_buffer) > 0 and (current_time - last_gesture_times.get(\"fist_time\", 0)) > 1.0:\n",
    "                shake_buffer = []\n",
    "\n",
    "        # --- Go Back / Forward by quick palm swipes (left/right short) ---\n",
    "        if vx < -1200 and time_since(\"go_back\") > gesture_cooldown:\n",
    "            pyautogui.hotkey(\"alt\", \"left\")\n",
    "            set_hud(\"Back\", \"back\")\n",
    "            set_gtime(\"go_back\")\n",
    "        if vx > 1200 and time_since(\"go_forward\") > gesture_cooldown:\n",
    "            pyautogui.hotkey(\"alt\", \"right\")\n",
    "            set_hud(\"Forward\", \"forward\")\n",
    "            set_gtime(\"go_forward\")\n",
    "\n",
    "        # --- Brightness Up / Down: index pointing up or down (only index up, others down) ---\n",
    "        if fup['index'] and not fup['middle'] and not fup['ring'] and not fup['pinky']:\n",
    "            idx_tip_y = hand_landmarks.landmark[8].y\n",
    "            idx_pip_y = hand_landmarks.landmark[6].y\n",
    "            if (idx_pip_y - idx_tip_y) > 0.08 and time_since(\"bright_up\") > 1.0:\n",
    "                execute_action(\"brightness_up\"); set_gtime(\"bright_up\")\n",
    "            if (idx_tip_y - idx_pip_y) > 0.08 and time_since(\"bright_down\") > 1.0:\n",
    "                execute_action(\"brightness_down\"); set_gtime(\"bright_down\")\n",
    "\n",
    "        # --- Mute: full fist (held) ---\n",
    "        if is_fist and time_since(\"mute\") > 1.5:\n",
    "            execute_action(\"mute\"); set_gtime(\"mute\")\n",
    "\n",
    "        # --- Task Manager: five fingers then fist sequence (sequence_buffer) ---\n",
    "        if fup['index'] and fup['middle'] and fup['ring'] and fup['pinky'] and fup['thumb']:\n",
    "            sequence_time = current_time\n",
    "            sequence_buffer.append((\"open_all\", current_time))\n",
    "            sequence_buffer = [s for s in sequence_buffer if current_time - s[1] < 1.5]\n",
    "        if is_fist:\n",
    "            sequence_buffer.append((\"fist\", current_time))\n",
    "            sequence_buffer = [s for s in sequence_buffer if current_time - s[1] < 1.5]\n",
    "            names = [s[0] for s in sequence_buffer]\n",
    "            if \"open_all\" in names and \"fist\" in names and time_since(\"taskmgr\") > 2.0:\n",
    "                execute_action(\"open_task_manager\")\n",
    "                set_gtime(\"taskmgr\")\n",
    "                sequence_buffer = []\n",
    "\n",
    "        # --- Lock screen: thumb + ring pinch (thumb + ring close) ---\n",
    "        thumb_ring_dist = distance(coords[4], coords[16])\n",
    "        if thumb_ring_dist < 35 and time_since(\"lock\") > 2.0:\n",
    "            execute_action(\"lock\"); set_gtime(\"lock\")\n",
    "\n",
    "        # update prev palm\n",
    "        prev_palm = palm\n",
    "        prev_time = current_time\n",
    "\n",
    "    else:\n",
    "        # no hand detected: clear some transient states\n",
    "        if dragging:\n",
    "            try:\n",
    "                pyautogui.mouseUp()\n",
    "            except Exception:\n",
    "                pass\n",
    "            dragging = False\n",
    "            set_hud(\"Drag Mode OFF\", \"drag\")\n",
    "            set_gtime(\"drag_end\")\n",
    "        # reset palm so velocities don't spike when hand reappears\n",
    "        prev_palm = None\n",
    "\n",
    "    # HUD\n",
    "    frame = draw_hud(frame) if 'draw_hud' in globals() else frame\n",
    "\n",
    "    # Show voice typing status\n",
    "    try:\n",
    "        cv2.putText(frame, f\"Voice Typing: {'ON' if voice_typing_enabled else 'OFF'}\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 230, 255), 2)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"HandVoice Controller HUD (Extended Gestures)\", frame)\n",
    "\n",
    "    # Use ESC to exit\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70a735-c892-438a-9dae-7fb123b27fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (MediaPipe)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
